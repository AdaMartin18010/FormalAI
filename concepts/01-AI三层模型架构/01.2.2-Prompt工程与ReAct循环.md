# 01.2.2-Prompt 工程与 ReAct 循环

## 一、概述

Prompt 工程与 ReAct 循环是控制层（形式语言模型）的核心技术，通过 Prompt 工程注入形式约束，通过 ReAct 循环实现思考-行动-观察的迭代过程。本文档阐述 Prompt 工程、ReAct 循环及其在 AI 系统中的应用。

---

## 二、目录

- [01.2.2-Prompt 工程与 ReAct 循环](#0122-prompt-工程与-react-循环)
  - [一、概述](#一概述)
  - [二、目录](#二目录)
  - [三、Prompt 工程](#三prompt-工程)
    - [2.1 Prompt 设计原则](#21-prompt-设计原则)
    - [2.2 Prompt 模板](#22-prompt-模板)
    - [2.3 Prompt 优化策略](#23-prompt-优化策略)
    - [2.4 2025 年最新 Prompt 技术](#24-2025-年最新-prompt-技术)
  - [四、ReAct 循环](#四react-循环)
    - [3.1 ReAct 定义](#31-react-定义)
    - [3.2 ReAct 实现](#32-react-实现)
    - [3.3 ReAct 优势与局限](#33-react-优势与局限)
    - [3.4 2025 年 ReAct 改进技术](#34-2025-年-react-改进技术)
  - [五、工程实践](#五工程实践)
    - [4.1 LangGraph 实现](#41-langgraph-实现)
    - [4.2 工程实践案例](#42-工程实践案例)
    - [4.3 2025 年产品案例](#43-2025-年产品案例)
  - [六、与三层模型的关系](#六与三层模型的关系)
    - [5.1 控制层 → 数据层](#51-控制层-数据层)
    - [5.2 控制层 → 执行层](#52-控制层-执行层)
  - [七、2025 年 Prompt 工程与 ReAct 技术趋势](#七2025-年-prompt-工程与-react-技术趋势)
  - [八、核心结论](#八核心结论)
  - [九、相关主题](#九相关主题)
  - [十、参考文档](#十参考文档)

## 三、Prompt 工程

### 2.1 Prompt 设计原则

**Prompt 设计原则**：

```mermaid
graph TB
    A[Prompt 设计] --> B[明确性]
    A --> C[结构化]
    A --> D[示例化]
    A --> E[约束化]

    B --> F[清晰的指令]
    C --> G[结构化的格式]
    D --> H[Few-shot 示例]
    E --> I[形式约束]

    style A fill:#f9f
    style F fill:#bfb
```

**Prompt 设计原则**：

1. **明确性**：指令清晰，避免歧义
2. **结构化**：使用结构化格式（JSON、Markdown）
3. **示例化**：提供 Few-shot 示例
4. **约束化**：添加形式约束（JSON Schema）

### 2.2 Prompt 模板

**Prompt 模板结构**：

```text
系统角色：定义 AI 的角色和职责
用户输入：用户的请求
上下文：相关背景信息
约束条件：形式约束（JSON Schema）
输出格式：期望的输出格式
```

**示例**：

````text
你是一个专业的代码审查助手。

用户输入：请审查以下代码
```python
def add(a, b):
    return a + b
````

约束条件：输出必须是 JSON 格式
{
"issues": [...],
"suggestions": [...]
}

输出格式：JSON

### 2.3 Prompt 优化策略

**Prompt 优化策略**：

| **策略**     | **方法**         | **效果**       | **成本**     |
| ------------ | ---------------- | -------------- | ------------ |
| **Few-shot** | 提供示例         | 准确率+10-20%  | 计算成本+20% |
| **CoT**      | 强制生成中间步骤 | 准确率+30-50%  | 计算成本+2x  |
| **角色扮演** | 定义角色和场景   | 准确率+5-10%   | 计算成本+10% |
| **约束解码** | JSON Schema 约束 | 格式正确率+95% | 计算成本+5%  |

### 2.4 2025 年最新 Prompt 技术

**System 1/2 混合（System 1/2 Hybrid）**：

**核心思想**：快速响应 + 慢速验证双系统调度

**System 1/2 混合流程**：

```mermaid
graph TB
    A[输入] --> B[System 1: 快速响应]
    A --> C[System 2: 慢速验证]
    B --> D[快速答案]
    C --> E[验证答案]
    D --> F[最终输出]
    E --> F

    style B fill:#bfb
    style C fill:#bbf
```

**2025 应用**：

- **Google Talker-Reasoner**：快速响应 + 慢速验证
- **OpenAI o1**：动态推理深度控制（CoT 长度自适应）
- **效果**：复杂任务效率提升 40%

**多模态 CoT（Multimodal CoT）**：

**核心思想**：文本、图像、视频统一 CoT 协议

**多模态 CoT 流程**：

```mermaid
graph LR
    A[文本输入] --> D[多模态 CoT]
    B[图像输入] --> D
    C[视频输入] --> D
    D --> E[统一推理链]
    E --> F[多模态输出]

    style D fill:#bfb
```

**2025 应用**：

- **Gemini 2.5**：多模态 CoT 统一协议
- **效果**：多模态融合效果好，支持超长上下文（1000K）

**动态推理深度（Dynamic Reasoning Depth）**：

**核心思想**：根据问题复杂度自适应调整推理深度

**动态推理深度流程**：

```mermaid
graph TB
    A[问题输入] --> B[复杂度评估]
    B --> C{复杂度}
    C -->|简单| D[浅层推理]
    C -->|中等| E[中层推理]
    C -->|复杂| F[深层推理]
    D --> G[输出]
    E --> G
    F --> G

    style B fill:#bfb
```

**2025 应用**：

- **OpenAI o1**：动态推理深度控制（CoT 长度自适应）
- **效果**：推理能力显著提升，支持复杂推理任务

**Test-time Compute（推理时计算扩展）**：

**核心思想**：不改变模型权重，通过增加推理时的计算资源激发潜在能力

**Test-time Compute 流程**：

```mermaid
graph TB
    A[输入] --> B[基础推理]
    B --> C[扩展推理]
    C --> D[多次采样]
    D --> E[投票/共识]
    E --> F[最终输出]

    style C fill:#bfb
```

**2025 应用**：

- **OpenAI o1**：Test-time compute 扩展（模拟推理链）
- **Meta PDR**：并行推理 → 提取共识 → 迭代优化
- **效果**：推理能力显著提升，无需重新训练

---

## 四、ReAct 循环

### 3.1 ReAct 定义

**ReAct（Reasoning + Acting）循环**：

**核心思想**：思考 → 行动 → 观察 → 思考的迭代过程

**循环流程**：

```mermaid
graph LR
    A[思考<br>Reasoning] --> B[行动<br>Acting]
    B --> C[观察<br>Observing]
    C --> D[评估]
    D -->|继续| A
    D -->|完成| E[输出]

    style A fill:#bbf
    style B fill:#bfb
    style C fill:#f9f
```

**ReAct 循环步骤**：

1. **思考（Reasoning）**：分析问题，制定计划
2. **行动（Acting）**：执行动作（工具调用、查询等）
3. **观察（Observing）**：观察结果，评估效果
4. **迭代**：根据观察结果调整策略，继续循环

### 3.2 ReAct 实现

**ReAct 实现框架**：

```python
class ReActAgent:
    def __init__(self, model, tools):
        self.model = model
        self.tools = tools
        self.history = []

    def react_loop(self, question, max_iter=10):
        for i in range(max_iter):
            # 思考：生成推理和行动
            reasoning, action = self.model.generate(
                prompt=self.build_prompt(question, self.history)
            )

            # 行动：执行工具调用
            if action.type == "tool_call":
                observation = self.tools.execute(action)
            else:
                observation = action.result

            # 观察：记录结果
            self.history.append({
                "reasoning": reasoning,
                "action": action,
                "observation": observation
            })

            # 评估：判断是否完成
            if self.is_complete(observation):
                return self.extract_answer(observation)

        return "无法完成"
```

### 3.3 ReAct 优势与局限

**ReAct 优势**：

1. **可解释性**：推理过程可解释
2. **可控性**：可控制推理步骤
3. **灵活性**：可动态调整策略

**ReAct 局限**：

1. **循环失控**：可能陷入死循环
2. **计算成本**：多次迭代增加计算成本
3. **状态管理**：需要管理历史状态

### 3.4 2025 年 ReAct 改进技术

**过程奖励模型（Process Reward Model, PRM）**：

**核心思想**：奖励推理过程，而非结果

**过程奖励 ReAct 流程**：

```mermaid
graph TB
    A[思考] --> B[行动]
    B --> C[观察]
    C --> D[过程奖励]
    D --> E{是否完成}
    E -->|否| A
    E -->|是| F[输出]

    style D fill:#bfb
```

**2025 应用**：

- **清华团队 PRM**：过程奖励模型
- **效果**：推理过程可解释，可控性强
- **局限**：依赖人工标注，标注成本高

**元思维链（Meta-CoT）**：

**核心思想**：不仅生成推理步骤，还模拟"如何思考"的元过程

**元思维链流程**：

```mermaid
graph TB
    A[问题] --> B[元思考: 如何思考]
    B --> C[推理步骤]
    C --> D[验证步骤]
    D --> E{是否完成}
    E -->|否| B
    E -->|是| F[输出]

    style B fill:#bfb
```

**2025 应用**：

- **研究探索**：元思维链在复杂推理任务中表现良好
- **效果**：支持回溯与验证，推理能力提升

**自我一致性（Self-Consistency）**：

**核心思想**：对同一问题采样多条推理路径，投票得最优解

**自我一致性流程**：

```mermaid
graph TB
    A[问题] --> B[路径1]
    A --> C[路径2]
    A --> D[路径N]
    B --> E[投票/共识]
    C --> E
    D --> E
    E --> F[最优解]

    style E fill:#bfb
```

**2025 应用**：

- **Meta PDR**：并行推理 → 提取共识 → 迭代优化
- **效果**：利用随机性对冲不确定性，准确率提升 5-10%

---

## 五、工程实践

### 4.1 LangGraph 实现

**LangGraph 框架**：

```mermaid
graph TB
    A[状态节点] --> B[工具调用节点]
    B --> C[观察节点]
    C --> D[决策节点]
    D -->|继续| A
    D -->|完成| E[输出节点]

    style A fill:#bbf
    style B fill:#bfb
    style C fill:#f9f
    style D fill:#ff9
```

**LangGraph 特点**：

- **状态机**：基于状态机的 ReAct 实现
- **持久化**：支持状态持久化
- **可视化**：支持可视化调试

### 4.2 工程实践案例

**案例 1：代码生成 Agent**：

```python
# ReAct 循环实现代码生成
def code_generation_agent(requirement):
    history = []
    for i in range(5):
        # 思考：分析需求
        reasoning = analyze_requirement(requirement, history)

        # 行动：生成代码
        code = generate_code(reasoning)

        # 观察：测试代码
        test_result = test_code(code)

        # 评估：判断是否完成
        if test_result.passed:
            return code

        history.append({
            "reasoning": reasoning,
            "code": code,
            "test_result": test_result
        })

    return "无法生成有效代码"
```

**案例 2：数据分析 Agent**：

```python
# ReAct 循环实现数据分析
def data_analysis_agent(question, data):
    history = []
    for i in range(10):
        # 思考：分析问题
        reasoning = analyze_question(question, data, history)

        # 行动：执行查询
        query = generate_query(reasoning)
        result = execute_query(query, data)

        # 观察：分析结果
        observation = analyze_result(result)

        # 评估：判断是否完成
        if observation.answerable:
            return observation.answer

        history.append({
            "reasoning": reasoning,
            "query": query,
            "result": result,
            "observation": observation
        })

    return "无法回答"
```

### 4.3 2025 年产品案例

**DeepSeek-R1 的 Prompt 工程**：

**特点**：

1. **纯 RL 驱动**：无 SFT 阶段，直接 RL 训练
2. **GRPO 对齐**：群体相对策略优化
3. **动态推理深度**：根据问题复杂度自适应调整

**效果**：推理能力显著提升，在数学推理任务上准确率提升 15-20%

**Claude 3.5 的 Prompt 工程**：

**特点**：

1. **Constitutional AI**：多阶段规则注入
2. **反向课程学习**：从复杂到简单
3. **RLHF 对齐**：人类反馈强化学习

**效果**：对齐效果好，可控性强，支持长上下文（200K）

**OpenAI o1 的 Prompt 工程**：

**特点**：

1. **动态推理深度控制**：CoT 长度自适应
2. **Test-time compute**：推理时计算扩展
3. **异步连续批处理**：提升推理效率

**效果**：推理能力显著提升，支持复杂推理任务

**Gemini 2.5 的 Prompt 工程**：

**特点**：

1. **多模态 CoT**：文本、图像、视频统一协议
2. **线性注意力**：支持超长上下文（1000K）
3. **TPU 优化**：TPU 多层流水线并行

**效果**：支持超长上下文，多模态融合效果好

---

## 六、与三层模型的关系

### 5.1 控制层 → 数据层

- **Prompt 转概率分布**：Prompt 将形式约束编码为条件概率
- **采样控制**：控制层控制采样策略（温度、top-k 等）

### 5.2 控制层 → 执行层

- **延迟约束**：控制层复杂度受执行层延迟限制
- **成本反馈**：控制层根据执行层成本调整策略

---

## 七、2025 年 Prompt 工程与 ReAct 技术趋势

**2025 年 Prompt 工程技术趋势**：

1. **System 1/2 混合**：快速响应 + 慢速验证，复杂任务效率提升 40%
2. **多模态 CoT**：文本、图像、视频统一协议，支持超长上下文
3. **动态推理深度**：根据问题复杂度自适应调整，推理能力显著提升
4. **Test-time Compute**：推理时计算扩展，无需重新训练即可提升能力

**2025 年 ReAct 改进技术趋势**：

1. **过程奖励模型（PRM）**：奖励推理过程，提升可解释性和可控性
2. **元思维链（Meta-CoT）**：模拟"如何思考"的元过程"，支持回溯与验证
3. **自我一致性**：多条推理路径投票，利用随机性对冲不确定性
4. **并行推理（PDR）**：并行推理 → 提取共识 → 迭代优化

**2025 年产品应用趋势**：

1. **DeepSeek-R1**：纯 RL 驱动 + GRPO 对齐 + 动态推理深度
2. **Claude 3.5**：Constitutional AI + 反向课程学习 + RLHF
3. **OpenAI o1**：动态推理深度控制 + Test-time compute + 异步批处理
4. **Gemini 2.5**：多模态 CoT + 线性注意力 + TPU 优化

---

## 八、核心结论

1. **Prompt 工程是控制层的核心技术**：通过 Prompt 注入形式约束，2025 年主流为 System 1/2 混合、多模态 CoT、动态推理深度、Test-time Compute
2. **ReAct 循环实现迭代推理**：思考 → 行动 → 观察的循环，2025 年改进为过程奖励、元思维链、自我一致性、并行推理
3. **LangGraph 是 ReAct 的工程实现**：基于状态机的框架，支持状态持久化和可视化调试
4. **工程实践需要平衡灵活性和可控性**：避免循环失控，需要设置最大迭代次数和超时机制
5. **2025 年趋势**：
   - **Prompt 工程**：System 1/2 混合、多模态 CoT、动态推理深度、Test-time Compute
   - **ReAct 改进**：过程奖励、元思维链、自我一致性、并行推理
   - **产品应用**：DeepSeek-R1、Claude 3.5、OpenAI o1、Gemini 2.5 等产品采用最新技术

---

## 九、相关主题

- [01.2.1-形式文法与 λ 演算](01.2.1-形式文法与λ演算.md)
- [01.2.3-控制层工具链与框架](01.2.3-控制层工具链与框架.md)
- [01.2.4-控制层约束与验证](01.2.4-控制层约束与验证.md)
- [01.3.3-概率采样与奖励塑形](01.3.3-概率采样与奖励塑形.md)：过程奖励模型（PRM）
- [01.4.1-三层协同机制](01.4.1-三层协同机制.md)：Prompt 工程与三层协同

---

## 十、参考文档

- [工程实践核心逻辑下的 AI 三层模型全景解构](../../view/ai_engineer_view.md)
- [分层解构视角](../../view/ai_models_view.md)

------

**最后更新**：2025-01-XX
**维护者**：FormalAI项目组