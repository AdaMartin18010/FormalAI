# 1.4 认知科学 / Cognitive Science / Kognitionswissenschaft / Sciences cognitives

## 概述 / Overview / Übersicht / Aperçu

认知科学研究人类认知过程的基本原理，为FormalAI提供智能系统设计和理解的理论基础。

Cognitive science studies the fundamental principles of human cognitive processes, providing theoretical foundations for intelligent system design and understanding in FormalAI.

Die Kognitionswissenschaft untersucht die grundlegenden Prinzipien menschlicher kognitiver Prozesse und liefert theoretische Grundlagen für das Design und Verständnis intelligenter Systeme in FormalAI.

Les sciences cognitives étudient les principes fondamentaux des processus cognitifs humains, fournissant les fondements théoriques pour la conception et la compréhension de systèmes intelligents dans FormalAI.

## 核心概念定义 / Core Concept Definitions / Kernbegriffsdefinitionen / Définitions des concepts fondamentaux

### 认知 / Cognition / Kognition / Cognition

**定义 / Definition / Definition / Définition:**

认知是信息处理、知识获取和智能行为的心智过程。

Cognition is the mental process of information processing, knowledge acquisition, and intelligent behavior.

Kognition ist der mentale Prozess der Informationsverarbeitung, Wissenserwerb und intelligentes Verhalten.

La cognition est le processus mental de traitement d'information, d'acquisition de connaissances et de comportement intelligent.

**内涵 / Intension / Intension / Intension:**

- 感知处理 / Perceptual processing / Wahrnehmungsverarbeitung / Traitement perceptuel
- 记忆存储 / Memory storage / Gedächtnisspeicherung / Stockage mémoriel
- 推理决策 / Reasoning and decision making / Schlussfolgerung und Entscheidungsfindung / Raisonnement et prise de décision
- 学习适应 / Learning and adaptation / Lernen und Anpassung / Apprentissage et adaptation

**外延 / Extension / Extension / Extension:**

- 注意机制 / Attention mechanisms / Aufmerksamkeitsmechanismen / Mécanismes d'attention
- 记忆系统 / Memory systems / Gedächtnissysteme / Systèmes de mémoire
- 语言处理 / Language processing / Sprachverarbeitung / Traitement du langage
- 问题解决 / Problem solving / Problemlösung / Résolution de problèmes

**属性 / Properties / Eigenschaften / Propriétés:**

- 并行处理 / Parallel processing / Parallele Verarbeitung / Traitement parallèle
- 模式识别 / Pattern recognition / Mustererkennung / Reconnaissance de patterns
- 抽象思维 / Abstract thinking / Abstraktes Denken / Pensée abstraite
- 创造性思维 / Creative thinking / Kreatives Denken / Pensée créative

## 目录 / Table of Contents / Inhaltsverzeichnis / Table des matières

- [1.4 认知科学 / Cognitive Science / Kognitionswissenschaft / Sciences cognitives](#14-认知科学--cognitive-science--kognitionswissenschaft--sciences-cognitives)
  - [概述 / Overview / Übersicht / Aperçu](#概述--overview--übersicht--aperçu)
  - [核心概念定义 / Core Concept Definitions / Kernbegriffsdefinitionen / Définitions des concepts fondamentaux](#核心概念定义--core-concept-definitions--kernbegriffsdefinitionen--définitions-des-concepts-fondamentaux)
    - [认知 / Cognition / Kognition / Cognition](#认知--cognition--kognition--cognition)
  - [目录 / Table of Contents / Inhaltsverzeichnis / Table des matières](#目录--table-of-contents--inhaltsverzeichnis--table-des-matières)
  - [1. 认知架构 / Cognitive Architecture / Kognitive Architektur / Architecture cognitive](#1-认知架构--cognitive-architecture--kognitive-architektur--architecture-cognitive)
    - [1.1 ACT-R架构 / ACT-R Architecture / ACT-R-Architektur / Architecture ACT-R](#11-act-r架构--act-r-architecture--act-r-architektur--architecture-act-r)
    - [1.2 SOAR架构 / SOAR Architecture / SOAR-Architektur / Architecture SOAR](#12-soar架构--soar-architecture--soar-architektur--architecture-soar)
    - [1.3 连接主义架构 / Connectionist Architecture / Konnektionistische Architektur / Architecture connexionniste](#13-连接主义架构--connectionist-architecture--konnektionistische-architektur--architecture-connexionniste)
  - [2. 记忆模型 / Memory Models / Gedächtnismodelle / Modèles de mémoire](#2-记忆模型--memory-models--gedächtnismodelle--modèles-de-mémoire)
    - [2.1 工作记忆 / Working Memory / Arbeitsgedächtnis / Mémoire de travail](#21-工作记忆--working-memory--arbeitsgedächtnis--mémoire-de-travail)
    - [2.2 长期记忆 / Long-term Memory / Langzeitgedächtnis / Mémoire à long terme](#22-长期记忆--long-term-memory--langzeitgedächtnis--mémoire-à-long-terme)
    - [2.3 记忆巩固 / Memory Consolidation / Gedächtniskonsolidierung / Consolidation mémorielle](#23-记忆巩固--memory-consolidation--gedächtniskonsolidierung--consolidation-mémorielle)
  - [3. 注意力机制 / Attention Mechanisms / Aufmerksamkeitsmechanismen / Mécanismes d'attention](#3-注意力机制--attention-mechanisms--aufmerksamkeitsmechanismen--mécanismes-dattention)
    - [3.1 选择性注意 / Selective Attention / Selektive Aufmerksamkeit / Attention sélective](#31-选择性注意--selective-attention--selektive-aufmerksamkeit--attention-sélective)
    - [3.2 分配性注意 / Divided Attention / Geteilte Aufmerksamkeit / Attention divisée](#32-分配性注意--divided-attention--geteilte-aufmerksamkeit--attention-divisée)
    - [3.3 执行控制 / Executive Control / Exekutive Kontrolle / Contrôle exécutif](#33-执行控制--executive-control--exekutive-kontrolle--contrôle-exécutif)
  - [4. 学习理论 / Learning Theories / Lerntheorien / Théories d'apprentissage](#4-学习理论--learning-theories--lerntheorien--théories-dapprentissage)
    - [4.1 经典条件反射 / Classical Conditioning / Klassische Konditionierung / Conditionnement classique](#41-经典条件反射--classical-conditioning--klassische-konditionierung--conditionnement-classique)
    - [4.2 操作性条件反射 / Operant Conditioning / Operante Konditionierung / Conditionnement opérant](#42-操作性条件反射--operant-conditioning--operante-konditionierung--conditionnement-opérant)
    - [4.3 认知学习 / Cognitive Learning / Kognitives Lernen / Apprentissage cognitif](#43-认知学习--cognitive-learning--kognitives-lernen--apprentissage-cognitif)
  - [5. 决策理论 / Decision Theory / Entscheidungstheorie / Théorie de la décision](#5-决策理论--decision-theory--entscheidungstheorie--théorie-de-la-décision)
    - [5.1 期望效用理论 / Expected Utility Theory / Erwartungsnutzentheorie / Théorie de l'utilité espérée](#51-期望效用理论--expected-utility-theory--erwartungsnutzentheorie--théorie-de-lutilité-espérée)
    - [5.2 前景理论 / Prospect Theory / Prospecttheorie / Théorie des perspectives](#52-前景理论--prospect-theory--prospecttheorie--théorie-des-perspectives)
    - [5.3 启发式决策 / Heuristic Decision Making / Heuristische Entscheidungsfindung / Prise de décision heuristique](#53-启发式决策--heuristic-decision-making--heuristische-entscheidungsfindung--prise-de-décision-heuristique)
  - [代码示例 / Code Examples / Codebeispiele / Exemples de code](#代码示例--code-examples--codebeispiele--exemples-de-code)
    - [Rust实现：认知架构模拟器 / Rust Implementation: Cognitive Architecture Simulator](#rust实现认知架构模拟器--rust-implementation-cognitive-architecture-simulator)
    - [Haskell实现：记忆模型 / Haskell Implementation: Memory Model](#haskell实现记忆模型--haskell-implementation-memory-model)
  - [参考文献 / References / Literatur / Références](#参考文献--references--literatur--références)

---

## 1. 认知架构 / Cognitive Architecture / Kognitive Architektur / Architecture cognitive

### 1.1 ACT-R架构 / ACT-R Architecture / ACT-R-Architektur / Architecture ACT-R

**ACT-R定义 / ACT-R Definition:**

ACT-R (Adaptive Control of Thought-Rational) 是一个认知架构，模拟人类认知过程。

ACT-R (Adaptive Control of Thought-Rational) is a cognitive architecture that simulates human cognitive processes.

ACT-R (Adaptive Control of Thought-Rational) ist eine kognitive Architektur, die menschliche kognitive Prozesse simuliert.

ACT-R (Adaptive Control of Thought-Rational) est une architecture cognitive qui simule les processus cognitifs humains.

**模块结构 / Module Structure:**

$$\text{ACT-R} = \{\text{Declarative}, \text{Procedural}, \text{Perceptual}, \text{Motor}\}$$

**声明性记忆 / Declarative Memory:**

声明性记忆存储事实性知识，采用激活扩散模型。

Declarative memory stores factual knowledge using a spreading activation model.

**激活函数 / Activation Function:**

$$A_i = B_i + \sum_{j \in S_i} W_j \cdot A_j$$

其中：

- $A_i$ 是节点 $i$ 的激活值
- $B_i$ 是基础激活值
- $S_i$ 是与节点 $i$ 相连的节点集合
- $W_j$ 是连接权重

**检索时间 / Retrieval Time:**

$$T = F \cdot e^{-A}$$

其中 $F$ 是时间因子，$A$ 是激活值。

### 1.2 SOAR架构 / SOAR Architecture / SOAR-Architektur / Architecture SOAR

**SOAR定义 / SOAR Definition:**

SOAR (State, Operator, And Result) 是一个统一的认知架构，基于问题空间假设。

SOAR (State, Operator, And Result) is a unified cognitive architecture based on the problem space hypothesis.

**问题空间 / Problem Space:**

$$\mathcal{P} = (S, O, G)$$

其中：

- $S$ 是状态集合
- $O$ 是操作集合
- $G$ 是目标状态集合

**决策周期 / Decision Cycle:**

1. **感知阶段 / Perception Phase:** 获取环境信息
2. **工作记忆更新 / Working Memory Update:** 更新当前状态
3. **偏好评估 / Preference Evaluation:** 评估操作偏好
4. **决策选择 / Decision Selection:** 选择最佳操作
5. **应用操作 / Operator Application:** 执行选定操作

### 1.3 连接主义架构 / Connectionist Architecture / Konnektionistische Architektur / Architecture connexionniste

**神经网络模型 / Neural Network Model:**

$$\mathbf{y} = f(\mathbf{W} \cdot \mathbf{x} + \mathbf{b})$$

其中：

- $\mathbf{x}$ 是输入向量
- $\mathbf{W}$ 是权重矩阵
- $\mathbf{b}$ 是偏置向量
- $f$ 是激活函数

**学习规则 / Learning Rule:**

$$\Delta w_{ij} = \eta \cdot \delta_i \cdot x_j$$

其中：

- $\eta$ 是学习率
- $\delta_i$ 是误差信号
- $x_j$ 是输入信号

## 2. 记忆模型 / Memory Models / Gedächtnismodelle / Modèles de mémoire

### 2.1 工作记忆 / Working Memory / Arbeitsgedächtnis / Mémoire de travail

**工作记忆容量 / Working Memory Capacity:**

$$C = 7 \pm 2 \text{ 个信息块}$$

**注意力控制 / Attentional Control:**

$$\text{Attention} = \frac{\text{Relevant Information}}{\text{Total Information}}$$

**认知负荷理论 / Cognitive Load Theory:**

$$\text{Load} = \text{Intrinsic} + \text{Extraneous} + \text{Germane}$$

### 2.2 长期记忆 / Long-term Memory / Langzeitgedächtnis / Mémoire à long terme

**记忆巩固 / Memory Consolidation:**

$$\frac{dM}{dt} = k \cdot (1 - M) \cdot S$$

其中：

- $M$ 是记忆强度
- $S$ 是刺激强度
- $k$ 是巩固常数

**遗忘曲线 / Forgetting Curve:**

$$R = e^{-\frac{t}{T}}$$

其中：

- $R$ 是保留率
- $t$ 是时间
- $T$ 是时间常数

### 2.3 记忆巩固 / Memory Consolidation / Gedächtniskonsolidierung / Consolidation mémorielle

**系统巩固 / Systems Consolidation:**

$$\text{Consolidation} = \text{Encoding} + \text{Storage} + \text{Retrieval}$$

**突触巩固 / Synaptic Consolidation:**

$$\Delta S = \alpha \cdot \text{Activity} \cdot \text{Reinforcement}$$

## 3. 注意力机制 / Attention Mechanisms / Aufmerksamkeitsmechanismen / Mécanismes d'attention

### 3.1 选择性注意 / Selective Attention / Selektive Aufmerksamkeit / Attention sélective

**过滤器模型 / Filter Model:**

$$
\text{Attention} = \begin{cases}
\text{Target} & \text{if } \text{Relevance} > \text{Threshold} \\
\text{Ignore} & \text{otherwise}
\end{cases}
$$

**衰减模型 / Attenuation Model:**

$$\text{Processing} = \text{Relevance} \cdot \text{Attention}$$

### 3.2 分配性注意 / Divided Attention / Geteilte Aufmerksamkeit / Attention divisée

**注意力分配 / Attention Allocation:**

$$\sum_{i=1}^{n} A_i \leq C$$

其中：

- $A_i$ 是任务 $i$ 的注意力分配
- $C$ 是总注意力容量

**多任务处理 / Multitasking:**

$$\text{Efficiency} = \frac{\sum_{i=1}^{n} P_i \cdot T_i}{\sum_{i=1}^{n} T_i}$$

### 3.3 执行控制 / Executive Control / Exekutive Kontrolle / Contrôle exécutif

**认知控制 / Cognitive Control:**

$$\text{Control} = \text{Inhibition} + \text{Shifting} + \text{Updating}$$

**工作记忆更新 / Working Memory Updating:**

$$\text{Update}(M, I) = M \setminus \text{Irrelevant} \cup I$$

## 4. 学习理论 / Learning Theories / Lerntheorien / Théories d'apprentissage

### 4.1 经典条件反射 / Classical Conditioning / Klassische Konditionierung / Conditionnement classique

**巴甫洛夫条件反射 / Pavlovian Conditioning:**

$$\text{Response} = \text{CS} \cdot \text{Association} + \text{US}$$

其中：

- $\text{CS}$ 是条件刺激
- $\text{US}$ 是无条件刺激
- $\text{Association}$ 是关联强度

**消退过程 / Extinction Process:**

$$\frac{dA}{dt} = -\alpha \cdot A$$

### 4.2 操作性条件反射 / Operant Conditioning / Operante Konditionierung / Conditionnement opérant

**强化学习 / Reinforcement Learning:**

$$Q(s, a) = Q(s, a) + \alpha \cdot [r + \gamma \cdot \max_{a'} Q(s', a') - Q(s, a)]$$

**强化计划 / Reinforcement Schedule:**

$$\text{Reinforcement} = f(\text{Response Rate}, \text{Schedule Type})$$

### 4.3 认知学习 / Cognitive Learning / Kognitives Lernen / Apprentissage cognitif

**图式理论 / Schema Theory:**

$$\text{Schema} = \text{Structure} + \text{Content} + \text{Process}$$

**认知地图 / Cognitive Map:**

$$\text{Map} = (V, E, \text{Spatial Relations})$$

## 5. 决策理论 / Decision Theory / Entscheidungstheorie / Théorie de la décision

### 5.1 期望效用理论 / Expected Utility Theory / Erwartungsnutzentheorie / Théorie de l'utilité espérée

**期望效用 / Expected Utility:**

$$EU(A) = \sum_{i=1}^{n} p_i \cdot u(x_i)$$

其中：

- $p_i$ 是结果 $i$ 的概率
- $u(x_i)$ 是结果 $i$ 的效用

**理性选择 / Rational Choice:**

$$A^* = \arg\max_{A \in \mathcal{A}} EU(A)$$

### 5.2 前景理论 / Prospect Theory / Prospecttheorie / Théorie des perspectives

**价值函数 / Value Function:**

$$
v(x) = \begin{cases}
x^\alpha & \text{if } x \geq 0 \\
-\lambda \cdot (-x)^\beta & \text{if } x < 0
\end{cases}
$$

**权重函数 / Weighting Function:**

$$\pi(p) = \frac{p^\gamma}{(p^\gamma + (1-p)^\gamma)^{1/\gamma}}$$

### 5.3 启发式决策 / Heuristic Decision Making / Heuristische Entscheidungsfindung / Prise de décision heuristique

**可用性启发式 / Availability Heuristic:**

$$\text{Probability} \propto \text{Ease of Retrieval}$$

**代表性启发式 / Representativeness Heuristic:**

$$\text{Similarity}(A, B) = \frac{|A \cap B|}{|A \cup B|}$$

**锚定启发式 / Anchoring Heuristic:**

$$\text{Estimate} = \text{Anchor} + \text{Adjustment}$$

## 代码示例 / Code Examples / Codebeispiele / Exemples de code

### Rust实现：认知架构模拟器 / Rust Implementation: Cognitive Architecture Simulator

```rust
use std::collections::HashMap;

/// 认知架构模拟器
/// Cognitive Architecture Simulator
pub struct CognitiveArchitecture {
    declarative_memory: HashMap<String, f64>,
    procedural_memory: HashMap<String, f64>,
    working_memory: Vec<String>,
    attention_focus: String,
}

impl CognitiveArchitecture {
    pub fn new() -> Self {
        Self {
            declarative_memory: HashMap::new(),
            procedural_memory: HashMap::new(),
            working_memory: Vec::new(),
            attention_focus: String::new(),
        }
    }
    
    /// 激活扩散 / Spreading Activation
    pub fn spreading_activation(&mut self, concept: &str, strength: f64) {
        let base_activation = self.declarative_memory.get(concept).unwrap_or(&0.0);
        let new_activation = base_activation + strength;
        self.declarative_memory.insert(concept.to_string(), new_activation);
        
        // 扩散到相关概念 / Spread to related concepts
        for (related_concept, relation_strength) in self.get_related_concepts(concept) {
            let current_activation = self.declarative_memory.get(&related_concept).unwrap_or(&0.0);
            let spread_activation = current_activation + strength * relation_strength * 0.5;
            self.declarative_memory.insert(related_concept, spread_activation);
        }
    }
    
    /// 注意力分配 / Attention Allocation
    pub fn allocate_attention(&mut self, task: &str, priority: f64) {
        let total_attention = 1.0;
        let current_allocation = self.get_attention_allocation();
        
        if current_allocation + priority <= total_attention {
            self.attention_focus = task.to_string();
        } else {
            // 重新分配注意力 / Reallocate attention
            self.attention_focus = task.to_string();
        }
    }
    
    /// 工作记忆更新 / Working Memory Update
    pub fn update_working_memory(&mut self, new_info: &str) {
        const WORKING_MEMORY_CAPACITY: usize = 7;
        
        if self.working_memory.len() >= WORKING_MEMORY_CAPACITY {
            // 移除最不重要的信息 / Remove least important information
            self.working_memory.remove(0);
        }
        
        self.working_memory.push(new_info.to_string());
    }
    
    /// 决策过程 / Decision Process
    pub fn make_decision(&self, options: &[String]) -> Option<String> {
        let mut best_option = None;
        let mut best_utility = f64::NEG_INFINITY;
        
        for option in options {
            let utility = self.calculate_utility(option);
            if utility > best_utility {
                best_utility = utility;
                best_option = Some(option.clone());
            }
        }
        
        best_option
    }
    
    /// 计算效用 / Calculate Utility
    fn calculate_utility(&self, option: &str) -> f64 {
        let activation = self.declarative_memory.get(option).unwrap_or(&0.0);
        let procedural_strength = self.procedural_memory.get(option).unwrap_or(&0.0);
        
        // 期望效用计算 / Expected utility calculation
        activation * 0.6 + procedural_strength * 0.4
    }
    
    /// 获取相关概念 / Get Related Concepts
    fn get_related_concepts(&self, concept: &str) -> Vec<(String, f64)> {
        // 简化的相关概念映射 / Simplified related concepts mapping
        match concept {
            "学习" => vec![("记忆".to_string(), 0.8), ("理解".to_string(), 0.7)],
            "记忆" => vec![("存储".to_string(), 0.9), ("检索".to_string(), 0.8)],
            "注意力" => vec![("专注".to_string(), 0.9), ("分散".to_string(), 0.6)],
            _ => vec![]
        }
    }
    
    /// 获取注意力分配 / Get Attention Allocation
    fn get_attention_allocation(&self) -> f64 {
        if self.attention_focus.is_empty() {
            0.0
        } else {
            0.8 // 假设80%的注意力分配给当前焦点
        }
    }
}

/// 记忆模型 / Memory Model
pub struct MemoryModel {
    short_term: Vec<String>,
    long_term: HashMap<String, f64>,
    consolidation_rate: f64,
}

impl MemoryModel {
    pub fn new() -> Self {
        Self {
            short_term: Vec::new(),
            long_term: HashMap::new(),
            consolidation_rate: 0.1,
        }
    }
    
    /// 记忆巩固 / Memory Consolidation
    pub fn consolidate(&mut self, concept: &str, strength: f64) {
        let current_strength = self.long_term.get(concept).unwrap_or(&0.0);
        let new_strength = current_strength + self.consolidation_rate * strength;
        self.long_term.insert(concept.to_string(), new_strength);
    }
    
    /// 遗忘过程 / Forgetting Process
    pub fn forget(&mut self, concept: &str, time_factor: f64) {
        if let Some(strength) = self.long_term.get_mut(concept) {
            let forgetting_rate = 0.05;
            *strength *= (1.0 - forgetting_rate * time_factor).max(0.0);
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_cognitive_architecture() {
        let mut ca = CognitiveArchitecture::new();
        
        // 测试激活扩散 / Test spreading activation
        ca.spreading_activation("学习", 0.8);
        assert!(ca.declarative_memory.get("学习").unwrap() > &0.0);
        
        // 测试注意力分配 / Test attention allocation
        ca.allocate_attention("数学", 0.7);
        assert_eq!(ca.attention_focus, "数学");
        
        // 测试工作记忆更新 / Test working memory update
        ca.update_working_memory("新信息");
        assert!(ca.working_memory.contains(&"新信息".to_string()));
    }
    
    #[test]
    fn test_memory_model() {
        let mut mm = MemoryModel::new();
        
        // 测试记忆巩固 / Test memory consolidation
        mm.consolidate("重要概念", 0.9);
        assert!(mm.long_term.get("重要概念").unwrap() > &0.0);
        
        // 测试遗忘过程 / Test forgetting process
        mm.consolidate("临时概念", 0.5);
        let initial_strength = mm.long_term.get("临时概念").unwrap().clone();
        mm.forget("临时概念", 1.0);
        assert!(mm.long_term.get("临时概念").unwrap() < &initial_strength);
    }
}
```

### Haskell实现：记忆模型 / Haskell Implementation: Memory Model

```haskell
-- 认知科学模块 / Cognitive Science Module
module CognitiveScience where

import Data.Map (Map)
import qualified Data.Map as Map
import Data.List (sortBy)
import Control.Monad.State

-- 记忆类型 / Memory Types
data MemoryType = Declarative | Procedural | Working deriving (Eq, Show)

-- 记忆项 / Memory Item
data MemoryItem = MemoryItem
    { content :: String
    , strength :: Double
    , memoryType :: MemoryType
    , timestamp :: Double
    } deriving (Show)

-- 认知状态 / Cognitive State
data CognitiveState = CognitiveState
    { declarativeMemory :: Map String Double
    , proceduralMemory :: Map String Double
    , workingMemory :: [String]
    , attentionFocus :: String
    , activationThreshold :: Double
    } deriving (Show)

-- 注意力机制 / Attention Mechanism
data AttentionMechanism = Selective | Divided | Executive deriving (Eq, Show)

-- 学习类型 / Learning Type
data LearningType = Classical | Operant | Cognitive deriving (Eq, Show)

-- 认知架构 / Cognitive Architecture
class CognitiveArchitecture a where
    process :: a -> String -> a
    learn :: a -> String -> LearningType -> a
    decide :: a -> [String] -> Maybe String

-- ACT-R架构实现 / ACT-R Architecture Implementation
data ACTR = ACTR
    { declarative :: Map String Double
    , procedural :: Map String Double
    , perceptual :: Map String Double
    , motor :: Map String Double
    } deriving (Show)

instance CognitiveArchitecture ACTR where
    process actr stimulus = actr { declarative = Map.insert stimulus 1.0 (declarative actr) }
    
    learn actr concept learningType = case learningType of
        Classical -> actr { declarative = Map.insert concept 0.8 (declarative actr) }
        Operant -> actr { procedural = Map.insert concept 0.9 (procedural actr) }
        Cognitive -> actr { declarative = Map.insert concept 0.7 (declarative actr) }
    
    decide actr options = 
        let utilities = map (\opt -> (opt, calculateUtility actr opt)) options
            sorted = sortBy (\a b -> compare (snd b) (snd a)) utilities
        in case sorted of
            [] -> Nothing
            (opt, _):_ -> Just opt

-- 计算效用 / Calculate Utility
calculateUtility :: ACTR -> String -> Double
calculateUtility actr option = 
    let declStrength = Map.findWithDefault 0.0 option (declarative actr)
        procStrength = Map.findWithDefault 0.0 option (procedural actr)
    in declStrength * 0.6 + procStrength * 0.4

-- 激活扩散 / Spreading Activation
spreadingActivation :: Map String Double -> String -> Double -> Map String Double
spreadingActivation memory concept strength = 
    let baseActivation = Map.findWithDefault 0.0 concept memory
        newActivation = baseActivation + strength
        updatedMemory = Map.insert concept newActivation memory
    in spreadToRelated updatedMemory concept strength

-- 扩散到相关概念 / Spread to Related Concepts
spreadToRelated :: Map String Double -> String -> Double -> Map String Double
spreadToRelated memory concept strength = 
    let relatedConcepts = getRelatedConcepts concept
        spreadStrength = strength * 0.5
    in foldl (\mem (related, relationStrength) -> 
        let currentActivation = Map.findWithDefault 0.0 related mem
            newActivation = currentActivation + strength * relationStrength * 0.5
        in Map.insert related newActivation mem) memory relatedConcepts

-- 获取相关概念 / Get Related Concepts
getRelatedConcepts :: String -> [(String, Double)]
getRelatedConcepts concept = case concept of
    "学习" -> [("记忆", 0.8), ("理解", 0.7)]
    "记忆" -> [("存储", 0.9), ("检索", 0.8)]
    "注意力" -> [("专注", 0.9), ("分散", 0.6)]
    _ -> []

-- 工作记忆模型 / Working Memory Model
data WorkingMemory = WorkingMemory
    { items :: [String]
    , capacity :: Int
    , focus :: String
    } deriving (Show)

-- 更新工作记忆 / Update Working Memory
updateWorkingMemory :: WorkingMemory -> String -> WorkingMemory
updateWorkingMemory wm newItem = 
    let currentItems = items wm
        maxCapacity = capacity wm
        updatedItems = if length currentItems >= maxCapacity
            then tail currentItems ++ [newItem]
            else currentItems ++ [newItem]
    in wm { items = updatedItems }

-- 注意力分配 / Attention Allocation
allocateAttention :: WorkingMemory -> String -> Double -> WorkingMemory
allocateAttention wm task priority = 
    let totalAttention = 1.0
        currentAllocation = getCurrentAttentionAllocation wm
    in if currentAllocation + priority <= totalAttention
        then wm { focus = task }
        else wm { focus = task } -- 简化版本，实际应该重新分配

-- 获取当前注意力分配 / Get Current Attention Allocation
getCurrentAttentionAllocation :: WorkingMemory -> Double
getCurrentAttentionAllocation wm = 
    if focus wm == ""
        then 0.0
        else 0.8 -- 假设80%的注意力分配给当前焦点

-- 记忆巩固模型 / Memory Consolidation Model
data MemoryConsolidation = MemoryConsolidation
    { consolidationRate :: Double
    , forgettingRate :: Double
    , timeFactor :: Double
    } deriving (Show)

-- 记忆巩固 / Memory Consolidation
consolidateMemory :: Map String Double -> String -> Double -> MemoryConsolidation -> Map String Double
consolidateMemory memory concept strength consolidation = 
    let currentStrength = Map.findWithDefault 0.0 concept memory
        rate = consolidationRate consolidation
        newStrength = currentStrength + rate * strength
    in Map.insert concept newStrength memory

-- 遗忘过程 / Forgetting Process
forgetMemory :: Map String Double -> String -> MemoryConsolidation -> Map String Double
forgetMemory memory concept consolidation = 
    case Map.lookup concept memory of
        Just strength -> 
            let rate = forgettingRate consolidation
                time = timeFactor consolidation
                newStrength = strength * (1.0 - rate * time)
            in Map.insert concept (max 0.0 newStrength) memory
        Nothing -> memory

-- 决策理论 / Decision Theory
data DecisionTheory = ExpectedUtility | ProspectTheory | Heuristic deriving (Eq, Show)

-- 期望效用决策 / Expected Utility Decision
expectedUtilityDecision :: [(String, Double, Double)] -> Maybe String
expectedUtilityDecision options = 
    let utilities = map (\(option, probability, utility) -> (option, probability * utility)) options
        totalUtility = sum $ map snd utilities
        bestOption = foldr (\a b -> if snd a > snd b then a else b) ("", 0.0) utilities
    in if totalUtility > 0.0 then Just (fst bestOption) else Nothing

-- 前景理论决策 / Prospect Theory Decision
prospectTheoryDecision :: [(String, Double, Double)] -> Maybe String
prospectTheoryDecision options = 
    let valueFunction x = if x >= 0 
        then x ** 0.88  -- α = 0.88
        else -2.25 * ((-x) ** 0.88)  -- λ = 2.25, β = 0.88
        weightedValues = map (\(option, probability, outcome) -> 
            (option, probability * valueFunction outcome)) options
        bestOption = foldr (\a b -> if snd a > snd b then a else b) ("", 0.0) weightedValues
    in if snd bestOption > 0.0 then Just (fst bestOption) else Nothing

-- 测试函数 / Test Functions
testCognitiveArchitecture :: IO ()
testCognitiveArchitecture = do
    let actr = ACTR Map.empty Map.empty Map.empty Map.empty
        learned = learn actr "数学" Classical
        processed = process learned "新概念"
        decision = decide processed ["选项A", "选项B", "选项C"]
    
    putStrLn "认知架构测试:"
    putStrLn $ "学习后: " ++ show learned
    putStrLn $ "处理后: " ++ show processed
    putStrLn $ "决策结果: " ++ show decision

testWorkingMemory :: IO ()
testWorkingMemory = do
    let wm = WorkingMemory [] 7 ""
        updated = updateWorkingMemory wm "新信息"
        focused = allocateAttention updated "重要任务" 0.8
    
    putStrLn "工作记忆测试:"
    putStrLn $ "更新后: " ++ show updated
    putStrLn $ "注意力分配后: " ++ show focused

testMemoryConsolidation :: IO ()
testMemoryConsolidation = do
    let memory = Map.fromList [("概念1", 0.5), ("概念2", 0.8)]
        consolidation = MemoryConsolidation 0.1 0.05 1.0
        consolidated = consolidateMemory memory "新概念" 0.9 consolidation
        forgotten = forgetMemory consolidated "概念1" consolidation
    
    putStrLn "记忆巩固测试:"
    putStrLn $ "巩固后: " ++ show consolidated
    putStrLn $ "遗忘后: " ++ show forgotten
```

## 参考文献 / References / Literatur / Références

*认知架构 / Cognitive Architecture*:

1. Anderson, J. R. (2007). How can the human mind occur in the physical universe? Oxford University Press.
2. Laird, J. E. (2012). The Soar cognitive architecture. MIT Press.
3. Newell, A. (1990). Unified theories of cognition. Harvard University Press.

*记忆模型 / Memory Models*:

1. Baddeley, A. D. (2000). The episodic buffer: a new component of working memory? Trends in Cognitive Sciences, 4(11), 417-423.
2. Ebbinghaus, H. (1885). Memory: A contribution to experimental psychology. Dover Publications.
3. Squire, L. R. (2004). Memory systems of the brain: A brief history and current perspective. Neurobiology of Learning and Memory, 82(3), 171-177.

*注意力机制 / Attention Mechanisms*:

1. Posner, M. I. (1980). Orienting of attention. Quarterly Journal of Experimental Psychology, 32(1), 3-25.
2. Kahneman, D. (1973). Attention and effort. Prentice-Hall.
3. Desimone, R., & Duncan, J. (1995). Neural mechanisms of selective visual attention. Annual Review of Neuroscience, 18(1), 193-222.

*学习理论 / Learning Theories*:

1. Pavlov, I. P. (1927). Conditioned reflexes. Oxford University Press.
2. Skinner, B. F. (1938). The behavior of organisms: An experimental analysis. Appleton-Century.
3. Piaget, J. (1952). The origins of intelligence in children. International Universities Press.

*决策理论 / Decision Theory*:

1. von Neumann, J., & Morgenstern, O. (1944). Theory of games and economic behavior. Princeton University Press.
2. Kahneman, D., & Tversky, A. (1979). Prospect theory: An analysis of decision under risk. Econometrica, 47(2), 263-291.
3. Gigerenzer, G., & Goldstein, D. G. (1996). Reasoning the fast and frugal way: Models of bounded rationality. Psychological Review, 103(4), 650-669.

*计算模型 / Computational Models*:

1. Rumelhart, D. E., McClelland, J. L., & PDP Research Group. (1986). Parallel distributed processing: Explorations in the microstructure of cognition. MIT Press.
2. McClelland, J. L., & Rumelhart, D. E. (1981). An interactive activation model of context effects in letter perception: Part 1. An account of basic findings. Psychological Review, 88(5), 375-407.
3. Anderson, J. R., & Lebiere, C. (1998). The atomic components of thought. Lawrence Erlbaum Associates.

*神经科学基础 / Neuroscience Foundations*:

1. Kandel, E. R., Schwartz, J. H., & Jessell, T. M. (2000). Principles of neural science. McGraw-Hill.
2. Bear, M. F., Connors, B. W., & Paradiso, M. A. (2016). Neuroscience: Exploring the brain. Lippincott Williams & Wilkins.
3. Purves, D., Augustine, G. J., Fitzpatrick, D., et al. (2018). Neuroscience. Sinauer Associates.

*认知发展 / Cognitive Development*:

1. Vygotsky, L. S. (1978). Mind in society: The development of higher psychological processes. Harvard University Press.
2. Bruner, J. S. (1960). The process of education. Harvard University Press.
3. Vygotsky, L. S. (1986). Thought and language. MIT Press.

*人工智能应用 / AI Applications*:

1. Russell, S. J., & Norvig, P. (2016). Artificial intelligence: A modern approach. Pearson.
2. Mitchell, T. M. (1997). Machine learning. McGraw-Hill.
3. Sutton, R. S., & Barto, A. G. (2018). Reinforcement learning: An introduction. MIT Press.

---

*认知科学为FormalAI提供了理解智能系统设计和人类认知过程的重要理论基础，通过形式化的方法将认知现象转化为可计算的模型。*

*Cognitive science provides FormalAI with important theoretical foundations for understanding intelligent system design and human cognitive processes, transforming cognitive phenomena into computable models through formal methods.*
